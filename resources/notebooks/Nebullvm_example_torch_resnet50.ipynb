{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nebullvm_example_torch_resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center> \n",
        "    <a href=\"https://discord.com/invite/RbeQMu886J\" target=\"_blank\" style=\"text-decoration: none;\"> Join the community </a> |\n",
        "    <a href=\"https://nebuly.gitbook.io/nebuly/welcome/questions-and-contributions\" target=\"_blank\" style=\"text-decoration: none;\"> Contribute to the library </a>\n",
        "</center>\n",
        "\n",
        "<center> \n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#how-nebullvm-works\" target=\"_blank\" style=\"text-decoration: none;\"> How nebullvm works </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#installation\" target=\"_blank\" style=\"text-decoration: none;\"> Installation </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#get-started\" target=\"_blank\" style=\"text-decoration: none;\"> Get Started </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#benchmarks\" target=\"_blank\" style=\"text-decoration: none;\"> Benchmarks </a>\n",
        "</center>"
      ],
      "metadata": {
        "id": "p5b0PzpW1xJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Accelerate PyTorch ResNet50 with nebullvm\n",
        "Hi and welcome ðŸ‘‹\n",
        "\n",
        "In this notebook we will discover how in just a few steps you can speed up the response time of deep learning model inference using the open-source library `nebullvm`.\n",
        "\n",
        "We will\n",
        "1. Install nebullvm and the deep learning compilers used by the library.\n",
        "2. Speed up a PyTorch ResNet50 without any loss of accuracy.\n",
        "3. Achieve faster acceleration on the same model by applying more aggressive optimization techniques (e.g. pruning, quantization) under the constraint of sacrificing up to 2% accuracy.\n",
        "\n",
        "Let's jump to the code."
      ],
      "metadata": {
        "id": "T9xuwZEHzN2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installation"
      ],
      "metadata": {
        "id": "HbFy2Aykz2Qo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPJHVZ74d8r2"
      },
      "outputs": [],
      "source": [
        "!pip install nebullvm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an optional step. Run it if you want to contribute to continuous improvement of `nebullvm` and share the performance achieved with it. You can find full details in the [docs](https://nebuly.gitbook.io/nebuly/nebullvm/how-nebullvm-works/fostering-continuous-improvement#sharing-feedback-to-improve-nebullvm)."
      ],
      "metadata": {
        "id": "wHvrcTYLz-dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_feedback = {\n",
        "    \"allow_feedback_collection\": True\n",
        "}\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "(Path.home() / \".nebullvm\").mkdir(exist_ok=True)\n",
        "with open(Path.home() / \".nebullvm/collect.json\", \"w\") as f:\n",
        "  json.dump(json_feedback, f)"
      ],
      "metadata": {
        "id": "UMjbl67gynsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now import nebullvm. During the import we will install the deep learning compilers used by nebullvm that are not yet installed on the hardware.\n",
        "\n",
        "The installation of the compilers may take a few minutes."
      ],
      "metadata": {
        "id": "b0CLgQqxyrQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nebullvm"
      ],
      "metadata": {
        "id": "GvK9mZSjeLU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization example with Pytorch"
      ],
      "metadata": {
        "id": "N5RXHoZl0p3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following example we will try to optimize a standard resnet50 loaded directly from torchvision.\n",
        "\n",
        "Nebullvm can accelerate neural networks without loss of a user-defined precision metric, e.g. accuracy, or can achieve faster acceleration by applying more aggressive optimization techniques, such as pruning and quantization, that may have a negative impact on the selectic metric. The maximum threshold value for accuracy loss is determined by the metric_drop_ths parameter. Read more in the [docs](https://nebuly.gitbook.io/nebuly/nebullvm/get-started).\n",
        "\n",
        "Let first test the optimization without accuracy loss (metric_drop_ths=0, default value), and then apply further accelerate it under the constrained of losing up to 2% of accuracy (metric = \"accuracy\", metric_drop_ths = 0.02)."
      ],
      "metadata": {
        "id": "-Ju-VcRH01Mw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 1 - No accuracy drop"
      ],
      "metadata": {
        "id": "skxEuemn171G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we load the model and optimize it using the nebullvm API:"
      ],
      "metadata": {
        "id": "wVRLXrDi2VaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "from nebullvm.api.functions import optimize_model\n",
        "\n",
        "# Load a resnet as example\n",
        "model = models.resnet50()\n",
        "\n",
        "# Provide an input data for the model    \n",
        "input_data = [((torch.randn(1, 3, 256, 256), ), 0)]\n",
        "\n",
        "# Run nebullvm optimization\n",
        "optimized_model = optimize_model(\n",
        "  model, input_data=input_data, optimization_time=\"unconstrained\"\n",
        ")\n",
        "\n",
        "# Try the optimized model\n",
        "x = torch.randn(1, 3, 256, 256)\n",
        "res = optimized_model(x)"
      ],
      "metadata": {
        "id": "2RbgGruAeQcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the optimization step, we can compare the optimized model with the baseline one in order to measure the speed improvement"
      ],
      "metadata": {
        "id": "JMiuufyu2gD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def benchmark(model, input_shape=(1, 3, 256, 256), nwarmup=50, nruns=1000):\n",
        "    input_data = torch.randn(input_shape)\n",
        "    input_data = input_data.to(device)\n",
        "\n",
        "    print(\"Warm up ...\")\n",
        "    with torch.no_grad():\n",
        "        for _ in range(nwarmup):\n",
        "            features = model(input_data)\n",
        "    torch.cuda.synchronize()\n",
        "    print(\"Start timing ...\")\n",
        "    timings = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(1, nruns+1):\n",
        "            start_time = time.time()\n",
        "            features = model(input_data)\n",
        "            torch.cuda.synchronize()\n",
        "            end_time = time.time()\n",
        "            timings.append(end_time - start_time)\n",
        "            if i%100==0:\n",
        "                print('Iteration %d/%d, avg batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
        "\n",
        "    if isinstance(features, tuple):\n",
        "      features = features[0]\n",
        "\n",
        "    print(\"Input shape:\", input_data.size())\n",
        "    print(\"Output features size:\", features.size())\n",
        "    print('Average throughput: %.2f images/second'%(input_shape[0]/np.mean(timings)))"
      ],
      "metadata": {
        "id": "GqxiCAbpfcwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to eval mode and move it to the available device\n",
        "\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "_0b0Bzwq-czD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we compute the average throughput for the baseline model:"
      ],
      "metadata": {
        "id": "UqxzStjD2v0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark(model)"
      ],
      "metadata": {
        "id": "dkt67_Orwlv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we compute the average throughput for the optimized model:\n",
        "\n"
      ],
      "metadata": {
        "id": "AgOv-GqQ3KIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark(optimized_model)"
      ],
      "metadata": {
        "id": "4PodpaDVfwzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scenario 2 - Accuracy drop"
      ],
      "metadata": {
        "id": "tBeRKNTI3iyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this scenario, we set a max threshold for the accuracy drop to 2%"
      ],
      "metadata": {
        "id": "w3wutIzfAMe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import torch\n",
        "#import torchvision.models as models\n",
        "#from nebullvm.api.functions import optimize_model\n",
        "\n",
        "## Load a resnet as example\n",
        "#model = models.resnet50()\n",
        "\n",
        "# Provide 100 random input data for the model  \n",
        "input_data = [((torch.randn(1, 3, 256, 256), ), 0) for _ in range(100)]\n",
        "\n",
        "# Run nebullvm optimization\n",
        "optimized_model = optimize_model(\n",
        "  model, input_data=input_data, optimization_time=\"unconstrained\", metric_drop_ths=0.02, metric=\"accuracy\"\n",
        ")\n",
        "\n",
        "# Try the optimized model\n",
        "x = torch.randn(1, 3, 256, 256)\n",
        "res = optimized_model(x)"
      ],
      "metadata": {
        "id": "fO1nGqpj3p7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to eval mode and move it to the available device\n",
        "\n",
        "# model.eval()\n",
        "# model.to(device)"
      ],
      "metadata": {
        "id": "qFKHaHM6-GKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we compute the average throughput for the baseline model:"
      ],
      "metadata": {
        "id": "yfW9kmHX-pGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark(model)"
      ],
      "metadata": {
        "id": "0MMrL3959hli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we compute the average throughput for the optimized model:"
      ],
      "metadata": {
        "id": "i3GqasOM-u8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark(optimized_model)"
      ],
      "metadata": {
        "id": "_IbAW0KA4Fm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> \n",
        "    <a href=\"https://discord.com/invite/RbeQMu886J\" target=\"_blank\" style=\"text-decoration: none;\"> Join the community </a> |\n",
        "    <a href=\"https://nebuly.gitbook.io/nebuly/welcome/questions-and-contributions\" target=\"_blank\" style=\"text-decoration: none;\"> Contribute to the library </a>\n",
        "</center>\n",
        "\n",
        "<center> \n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#how-nebullvm-works\" target=\"_blank\" style=\"text-decoration: none;\"> How nebullvm works </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#installation\" target=\"_blank\" style=\"text-decoration: none;\"> Installation </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#get-started\" target=\"_blank\" style=\"text-decoration: none;\"> Get Started </a> â€¢\n",
        "    <a href=\"https://github.com/nebuly-ai/nebullvm#benchmarks\" target=\"_blank\" style=\"text-decoration: none;\"> Benchmarks </a>\n",
        "</center>"
      ],
      "metadata": {
        "id": "xLBCDOTS10L6"
      }
    }
  ]
}